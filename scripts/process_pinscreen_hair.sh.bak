#!/bin/bash
# resample all hairstyles to ~10,000 strands per hairstyle
python src/preprocess.py -p resample -i /home/chhe/proj_nmsh/stylist/data/output/hair-resampled/data/ -o ./data/resample
python src/preprocess.py -p resample -i /home/chhe/proj_nmsh/stylist/data/output/hair-resampled-curly-1/data/ -o ./data/resample
python src/preprocess.py -p resample -i /home/chhe/proj_nmsh/stylist/data/output/hair-resampled-curly-2/data/ -o ./data/resample
# cluster strands to form wisps and compute guide strands
python src/preprocess.py -p wisp -i ./data/resample/data -o ./data/wisps --n_clusters 100
# python src/preprocess.py -d collision -i ./data/wisps -o ./data/wisps
# decompose hairstyles to obtain local strands and residuals
python src/preprocess.py -p hair -i ./data/resample/data -o ./data/hair --wisp ./data/wisps --global_rot

# python src/datasets/preprocess.py -d global -i /home/chhe/proj_hair/stylist/data/output/hair-resampled/data/ -o ./data/hair/strand_codec/global --global_rot
# python src/datasets/preprocess.py -d global -i /home/chhe/proj_hair/stylist/data/output/hair-resampled-curly-1/data/ -o ./data/hair/strand_codec/global --global_rot
# python src/datasets/preprocess.py -d global -i /home/chhe/proj_hair/stylist/data/output/hair-resampled-curly-2/data/ -o ./data/hair/strand_codec/global --global_rot

# python src/datasets/preprocess.py -d local -i /home/chhe/proj_hair/stylist/data/output/hair-resampled/data/ -o ./data/hair/strand_codec/local --n_clusters 100 --global_rot
# python src/datasets/preprocess.py -d local -i /home/chhe/proj_hair/stylist/data/output/hair-resampled-curly-1/data/ -o ./data/hair/strand_codec/local --n_clusters 100 --global_rot
# python src/datasets/preprocess.py -d local -i /home/chhe/proj_hair/stylist/data/output/hair-resampled-curly-2/data/ -o ./data/hair/strand_codec/local --n_clusters 100 --global_rot

# python src/datasets/preprocess.py -d global -i ./data/resample/data -o ./data/hair/neural_texture/global --global_rot
# python src/datasets/preprocess.py -d local -i ./data/resample/data -o ./data/hair/neural_texture/local --n_clusters 100 --global_rot

# compute mean and std of the decomposed datasets and store them in a cache file
python src/preprocess.py -p normalize -i data/hair -o data/hair/strands_cache --data_keys position rotation length --range 0 1080 --reduction cat --cache --cache_file strands.pt
python src/preprocess.py -p normalize -i data/hair -o data/hair/guide_strands_cache --data_keys position_guide rotation_guide length_guide --range 0 1080 --reduction cat --cache --cache_file guide_strands.pt
python src/preprocess.py -p normalize -i data/hair -o data/hair/local_strands_cache --data_keys position_local rotation_local length_local --range 1000 1080 --reduction cat --cache --cache_file local_strands.pt
python src/preprocess.py -p normalize -i data/hair -o data/hair/residual_cache --data_keys residual_local --range 1000 1080 --reduction cat --cache --cache_file residual.pt